{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ef1f98-1ea2-43c8-a107-baffe0a683c2",
   "metadata": {},
   "source": [
    "# First attempt at a world model\n",
    "## Basic Process"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf9e38bc-4bf6-4d76-9d88-a6bc2b1f5844",
   "metadata": {},
   "source": [
    "Cost training (* is trainable)\n",
    "-------------------------------\n",
    "Frame 0 Sensor Input-->Encoder*-->Cost*-->MSE (w/ real cost)\n",
    "Encoder and Predictor Training\n",
    "-------------------------------\n",
    "Frame 0 Sensor Input-->Encoder-\\\n",
    "                                Predictor*\\\n",
    "         Frame 0 Control Input-/           \\\n",
    "           Frame 1 Sensor Input-->Encoder-->MSE\n",
    "Action generator training\n",
    "-------------------------------\n",
    "Frame 0 Sensor Input-->Encoder------------------\\\n",
    "                              \\                  Predictor-->Cost (Minimize cost output)\n",
    "                               Action Generator*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c5a29d-5b2c-464c-aaac-51b68ef45eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 20:59:54.397152: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-28 20:59:54.472649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 20:59:55.220731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Settings and setup\n",
    "import tensorflow as tf\n",
    "\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Main Settings\n",
    "ROLE = \"TAGGER\"\n",
    "\n",
    "# Encoder Settings\n",
    "IMG_INPUT_SHAPE=(640, 640, 3)\n",
    "\n",
    "NUM_DBS = 8\n",
    "NUM_LAYERS_PER_DB = 1\n",
    "NUM_FILTERS_PER_LAYER_OF_DB = 2\n",
    "\n",
    "DOWNSCALING_LAYERS = 4\n",
    "DOWNSCALING_FACTOR = 2\n",
    "OUTPUT_SIZE = 32\n",
    "ENC_DROPOUT = 0.25\n",
    "\n",
    "# PREDICTOR\n",
    "PRED_INTER_LAYERS = 3\n",
    "PRED_INTER_LAYER_SIZE = 64\n",
    "PRED_DROPOUT = 0.25\n",
    "\n",
    "# Action Generator Settings\n",
    "ACTIONS = 4\n",
    "ACT_INTER_LAYERS = 5\n",
    "ACT_INTER_LAYER_SIZE = 1024\n",
    "ACT_DROPOUT = 0.1\n",
    "\n",
    "# Cost Calculator Settings\n",
    "CC_INTER_LAYERS = 3\n",
    "CC_INTER_LAYER_SIZE = 64\n",
    "CC_DROPOUT = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64458f8c-cece-4be4-bf34-147ca1ed8834",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8779741b-ffda-4856-a096-b653fab49025",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 20:59:56.239253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:18:00.0, compute capability: 8.9\n",
      "2023-09-28 20:59:56.239870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22451 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:af:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 640, 640, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 640, 640, 2)          488       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 640, 640, 4)          204       ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 640, 640, 6)          0         ['conv2d[0][0]',              \n",
      "                                                                     'conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 640, 640, 4)          28        ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 320, 320, 4)          0         ['conv2d_2[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 320, 320, 6)          606       ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 320, 320, 10)         0         ['max_pooling2d[0][0]',       \n",
      " )                                                                   'conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 320, 320, 6)          66        ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 160, 160, 6)          0         ['conv2d_4[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 160, 160, 8)          1208      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 160, 160, 14)         0         ['max_pooling2d_1[0][0]',     \n",
      " )                                                                   'conv2d_5[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 160, 160, 8)          120       ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 80, 80, 8)            0         ['conv2d_6[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 80, 80, 10)           2010      ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 80, 80, 18)           0         ['max_pooling2d_2[0][0]',     \n",
      " )                                                                   'conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 80, 80, 10)           190       ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 40, 40, 10)           0         ['conv2d_8[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 40, 40, 12)           3012      ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 40, 40, 22)           0         ['max_pooling2d_3[0][0]',     \n",
      " )                                                                   'conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 40, 40, 12)           276       ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 20, 20, 12)           0         ['conv2d_10[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 20, 20, 14)           4214      ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 20, 20, 26)           0         ['max_pooling2d_4[0][0]',     \n",
      " )                                                                   'conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 20, 20, 14)           378       ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 10, 10, 14)           0         ['conv2d_12[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 10, 10, 16)           5616      ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate  (None, 10, 10, 30)           0         ['max_pooling2d_5[0][0]',     \n",
      " )                                                                   'conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 10, 10, 16)           496       ['concatenate_6[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 5, 5, 16)             0         ['conv2d_14[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 5, 5, 18)             7218      ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate  (None, 5, 5, 34)             0         ['max_pooling2d_6[0][0]',     \n",
      " )                                                                   'conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 5, 5, 18)             630       ['concatenate_7[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 2, 2, 18)             0         ['conv2d_16[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 2, 2, 20)             9020      ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate  (None, 2, 2, 38)             0         ['max_pooling2d_7[0][0]',     \n",
      " )                                                                   'conv2d_17[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 35780 (139.77 KB)\n",
      "Trainable params: 35780 (139.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Image segmenter base\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_dense_block(x, num_of_layers, num_filters, kernel_size=5):\n",
    "    output_layers = [x]\n",
    "    for l in range(num_of_layers):\n",
    "        x = layers.Conv2D(num_filters, kernel_size, activation=\"elu\", padding=\"same\")(x)\n",
    "        output_layers.append(x)\n",
    "        x = layers.Concatenate()(output_layers)\n",
    "    return x\n",
    "\n",
    "def create_transistion_down(x, layer_size_change, num_filters=None):\n",
    "    if num_filters:\n",
    "        x = layers.Conv2D(num_filters, 1, activation=\"elu\", padding=\"same\")(x)\n",
    "    \n",
    "    return layers.MaxPool2D(layer_size_change)(x)\n",
    "\n",
    "# Keep track for skip connections and other things\n",
    "skip_connections = []\n",
    "previous_filters = [NUM_LAYERS_PER_DB * NUM_FILTERS_PER_LAYER_OF_DB]\n",
    "\n",
    "# Num of filters: 4 (layers) * 32 (idk) + 64 (previous filters)\n",
    "# Should prob figure out why this is\n",
    "\n",
    "model_in = layers.Input(shape=IMG_INPUT_SHAPE)\n",
    "x = layers.Conv2D(previous_filters[-1], 9, activation=\"elu\", padding=\"same\")(model_in)\n",
    "\n",
    "for i in range(NUM_DBS):\n",
    "    previous_filters.append(NUM_LAYERS_PER_DB * NUM_FILTERS_PER_LAYER_OF_DB + previous_filters[-1])\n",
    "    x = create_dense_block(x, NUM_LAYERS_PER_DB, previous_filters[-1])\n",
    "    skip_connections.append(x)\n",
    "    x = create_transistion_down(x, 2, num_filters=(previous_filters[-1]))\n",
    "\n",
    "\n",
    "previous_filters.append(NUM_LAYERS_PER_DB * NUM_FILTERS_PER_LAYER_OF_DB + previous_filters[-1])\n",
    "x = create_dense_block(x, NUM_LAYERS_PER_DB, previous_filters[-1]) \n",
    "\n",
    "dense_net = models.Model(model_in, x)\n",
    "\n",
    "dense_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4136aa64-ad4b-4d0a-8a16-9218289b1c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " random_flip (RandomFlip)    (None, 640, 640, 3)       0         \n",
      "                                                                 \n",
      " model (Functional)          (None, 2, 2, 38)          35780     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 152)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               78336     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32)                128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 288804 (1.10 MB)\n",
      "Trainable params: 288740 (1.10 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Encoder (Simple downscaler)\n",
    "\n",
    "# Added encoder to flatten dense_net\n",
    "encoder = models.Sequential()\n",
    "encoder.add(layers.Input(shape=IMG_INPUT_SHAPE))\n",
    "encoder.add(layers.RandomFlip())\n",
    "encoder.add(dense_net)\n",
    "encoder.add(layers.Flatten())\n",
    "\n",
    "for i in range(DOWNSCALING_LAYERS + 1):\n",
    "    encoder.add(layers.Dense(DOWNSCALING_FACTOR**(DOWNSCALING_LAYERS-i) * OUTPUT_SIZE, activation=\"elu\", kernel_regularizer='l2'))\n",
    "    encoder.add(layers.Dropout(ENC_DROPOUT))\n",
    "\n",
    "encoder.add(layers.BatchNormalization())\n",
    "\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720b06d-d2dd-43e6-8cf7-3b12025a5912",
   "metadata": {},
   "source": [
    "# Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e81c043-2a8c-4297-b625-eaa1a444cf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                2368      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12768 (49.88 KB)\n",
      "Trainable params: 12768 (49.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "curr_shape = OUTPUT_SIZE + ACTIONS\n",
    "\n",
    "predictor = models.Sequential()\n",
    "predictor.add(layers.Input(shape=curr_shape))\n",
    "\n",
    "# Add internal layers\n",
    "for _ in range(PRED_INTER_LAYERS):\n",
    "    predictor.add(layers.Dense(PRED_INTER_LAYER_SIZE, activation=\"elu\", kernel_regularizer='l2'))\n",
    "    predictor.add(layers.Dropout(PRED_DROPOUT))\n",
    "\n",
    "\n",
    "predictor.add(layers.Dense(OUTPUT_SIZE, activation=\"elu\"))\n",
    "\n",
    "predictor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4872c-0152-4ca3-a285-70083d5cb72f",
   "metadata": {},
   "source": [
    "# Cost Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361973ee-4a46-421d-a532-a21313fd8860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13057 (51.00 KB)\n",
      "Trainable params: 13057 (51.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cost_calculator = models.Sequential()\n",
    "cost_calculator.add(layers.Input(shape=OUTPUT_SIZE))\n",
    "\n",
    "# Add internal layers\n",
    "for _ in range(CC_INTER_LAYERS):\n",
    "    cost_calculator.add(layers.Dense(CC_INTER_LAYER_SIZE, activation=\"elu\", kernel_regularizer='l2'))\n",
    "    cost_calculator.add(layers.Dropout(CC_DROPOUT))\n",
    "\n",
    "cost_calculator.add(layers.Dense(CC_INTER_LAYER_SIZE//2, activation=\"elu\"))\n",
    "cost_calculator.add(layers.Dense(CC_INTER_LAYER_SIZE//4, activation=\"elu\"))\n",
    "cost_calculator.add(layers.Dense(1, activation=\"elu\"))\n",
    "\n",
    "cost_calculator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c56de9b-aa4b-4e1b-bb3a-76a3d3775c96",
   "metadata": {},
   "source": [
    "## Action Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "571242d5-d8d9-41c5-ad29-89337d84d86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 1024)              33792     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 132       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4931684 (18.81 MB)\n",
      "Trainable params: 4931684 (18.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "action_gen = models.Sequential()\n",
    "action_gen.add(layers.Input(shape=OUTPUT_SIZE))\n",
    "\n",
    "# Add internal layers\n",
    "for _ in range(ACT_INTER_LAYERS):\n",
    "    action_gen.add(layers.Dense(ACT_INTER_LAYER_SIZE, activation=\"elu\"))\n",
    "    action_gen.add(layers.Dropout(ACT_DROPOUT))\n",
    "\n",
    "action_gen.add(layers.Dense(ACT_INTER_LAYER_SIZE//2, activation=\"elu\"))\n",
    "action_gen.add(layers.Dense(ACT_INTER_LAYER_SIZE//4, activation=\"elu\"))\n",
    "action_gen.add(layers.Dense(ACT_INTER_LAYER_SIZE//8, activation=\"elu\"))\n",
    "action_gen.add(layers.Dense(ACT_INTER_LAYER_SIZE//16, activation=\"elu\"))\n",
    "action_gen.add(layers.Dense(ACT_INTER_LAYER_SIZE//32, activation=\"elu\"))\n",
    "action_gen.add(layers.Dense(ACTIONS, activation=\"sigmoid\"))\n",
    "    \n",
    "action_gen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fed330-69b5-4ed6-b1e7-227fa4954474",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25596b47-162b-4fe4-b584-bfb92df241b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open data and convert to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4151f1c3-3852-4453-bc4b-88d083a750b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "ENCODER_AND_COST_LR = 0.00001\n",
    "PRED_LR = 0.000005\n",
    "ACT_GEN_LR = 0.000001\n",
    "\n",
    "MAX_EPOCHS = 100\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11328cac-e8a3-4292-b04b-7a6ede8a5427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1695099029\n",
      "1695098660\n",
      "1695098329\n",
      "1695100432\n",
      "1695100581\n",
      "1695098876\n",
      "1695099103\n",
      "1695098364\n",
      "1695098432\n",
      "1695098474\n",
      "1695100250\n",
      "1695098472\n",
      "1695099810\n",
      "1695098637\n",
      "1695098337\n",
      "1695098372\n",
      "1695098527\n",
      "1695098388\n",
      "1695100469\n",
      "1695100199\n",
      "1695098347\n",
      "1695100607\n",
      "1695098502\n",
      "1695098542\n",
      "1695100270\n",
      "1695098724\n",
      "1695100353\n",
      "1695099903\n",
      "1695098609\n",
      "1695100371\n",
      "tf.Tensor([12514   640   640     3], shape=(4,), dtype=int32) tf.Tensor([12514   640   640     3], shape=(4,), dtype=int32) tf.Tensor([12514     4], shape=(2,), dtype=int32) tf.Tensor([12514], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "with tf.device(\"cpu:0\"):\n",
    "    runs = pd.read_csv(\"game_runs.csv\")[[\"Run\", \"Winner\"]].sample(frac=1).values.tolist()\n",
    "    all_frames = []\n",
    "    all_next_frames = []\n",
    "    all_input = []\n",
    "    all_scores = []\n",
    "    for run, winner in runs[:30]:\n",
    "        frames = tf.cast(tf.io.parse_tensor(tf.io.read_file(\"runs/%d/frames.proto_tensor\" % run), tf.uint8), tf.float16)/255.0\n",
    "        all_frames.append(frames)\n",
    "    \n",
    "        if ROLE == \"TAGGER\":\n",
    "            all_input.append(tf.io.parse_tensor(tf.io.read_file(\"runs/%d/tagger_inputs.proto_tensor\" % run), float))\n",
    "        else:\n",
    "            all_input.append(tf.io.parse_tensor(tf.io.read_file(\"runs/%d/taggee_inputs.proto_tensor\" % run), float))\n",
    "    \n",
    "        tagger_poses = tf.io.parse_tensor(tf.io.read_file(\"runs/%d/tagger_poses.proto_tensor\" % run), float)\n",
    "        taggee_poses = tf.io.parse_tensor(tf.io.read_file(\"runs/%d/taggee_poses.proto_tensor\" % run), float)\n",
    "    \n",
    "        scores_normalizer = tf.math.sqrt(tf.cast(tf.math.square(IMG_INPUT_SHAPE[0]) + tf.math.square(IMG_INPUT_SHAPE[1]), float))\n",
    "        \n",
    "        if ROLE == \"TAGGER\":\n",
    "            scores = tf.math.sqrt(tf.math.reduce_sum(tf.math.square(tagger_poses - taggee_poses), axis=1))/scores_normalizer\n",
    "        else:\n",
    "            scores = (scores_normalizer - tf.math.sqrt(tf.math.reduce_sum(tf.math.square(tagger_poses - taggee_poses), axis=1)))/scores_normalizer\n",
    "        \n",
    "        if winner != ROLE:\n",
    "            scores = tf.concat([scores[:-5:], tf.repeat(tf.constant([1.0]), repeats=5)], axis=0)\n",
    "        all_scores.append(scores)\n",
    "        print(run)\n",
    "\n",
    "    all_next_frames = tf.concat([frame[1:] for frame in all_frames], axis=0)\n",
    "    all_frames = tf.concat([frame[:-1] for frame in all_frames], axis=0)\n",
    "    all_input = tf.cast(tf.concat([input[:-1] for input in all_input], axis=0), tf.float16)\n",
    "    all_scores = tf.cast(tf.concat([scores[:-1] for scores in all_scores], axis=0), tf.float16)\n",
    "    \n",
    "    print(tf.shape(all_frames), tf.shape(all_next_frames), tf.shape(all_input), tf.shape(all_scores))\n",
    "    \n",
    "    big_train_ds = tf.data.Dataset.from_tensor_slices((all_frames, all_next_frames, all_input, tf.expand_dims(all_scores, axis=-1)))\n",
    "    big_train_ds = big_train_ds.shuffle(big_train_ds.cardinality())\n",
    "    big_valid_ds = big_train_ds.shard(8, 6)\n",
    "    big_test_ds = big_train_ds.shard(8, 7)\n",
    "    big_train_ds = big_train_ds.take((6 * big_train_ds.cardinality())//8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88cbca5e-3d17-4fbb-9370-34a796c3dc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 32)                288804    \n",
      "                                                                 \n",
      " sequential_2 (Sequential)   (None, 1)                 13057     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301861 (1.15 MB)\n",
      "Trainable params: 301797 (1.15 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 21:01:09.358644: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8904\n",
      "2023-09-28 21:01:09.507431: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2023-09-28 21:01:09.507464: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-09-28 21:01:09.507571: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2023-09-28 21:01:10.568753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-09-28 21:01:10.604657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2238d5dcb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-28 21:01:10.604683: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2023-09-28 21:01:10.604691: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2023-09-28 21:01:10.611608: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-28 21:01:10.699928: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587/587 [==============================] - 67s 92ms/step - loss: 10.5939 - mse: 0.3506 - val_loss: 10.1062 - val_mse: 0.0728\n",
      "Epoch 2/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 10.0172 - mse: 0.2000 - val_loss: 9.6334 - val_mse: 0.0369\n",
      "Epoch 3/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 9.5128 - mse: 0.1433 - val_loss: 9.1656 - val_mse: 0.0273\n",
      "Epoch 4/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 9.0127 - mse: 0.1110 - val_loss: 8.6828 - val_mse: 0.0221\n",
      "Epoch 5/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 8.5077 - mse: 0.0925 - val_loss: 8.1873 - val_mse: 0.0211\n",
      "Epoch 6/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 7.9910 - mse: 0.0766 - val_loss: 7.6784 - val_mse: 0.0188\n",
      "Epoch 7/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 7.4672 - mse: 0.0645 - val_loss: 7.1618 - val_mse: 0.0189\n",
      "Epoch 8/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 6.9360 - mse: 0.0545 - val_loss: 6.6357 - val_mse: 0.0178\n",
      "Epoch 9/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 6.4044 - mse: 0.0490 - val_loss: 6.1099 - val_mse: 0.0178\n",
      "Epoch 10/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 5.8742 - mse: 0.0424 - val_loss: 5.5907 - val_mse: 0.0191\n",
      "Epoch 11/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 5.3511 - mse: 0.0353 - val_loss: 5.0814 - val_mse: 0.0208\n",
      "Epoch 12/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 4.8400 - mse: 0.0283 - val_loss: 4.5815 - val_mse: 0.0180\n",
      "Epoch 13/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 4.3423 - mse: 0.0228 - val_loss: 4.0929 - val_mse: 0.0179\n",
      "Epoch 14/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 3.8537 - mse: 0.0198 - val_loss: 3.6094 - val_mse: 0.0161\n",
      "Epoch 15/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 3.3774 - mse: 0.0183 - val_loss: 3.1427 - val_mse: 0.0153\n",
      "Epoch 16/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 2.9232 - mse: 0.0171 - val_loss: 2.7022 - val_mse: 0.0131\n",
      "Epoch 17/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 2.5009 - mse: 0.0150 - val_loss: 2.3020 - val_mse: 0.0133\n",
      "Epoch 18/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 2.1192 - mse: 0.0120 - val_loss: 1.9416 - val_mse: 0.0092\n",
      "Epoch 19/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 1.7847 - mse: 0.0107 - val_loss: 1.6314 - val_mse: 0.0088\n",
      "Epoch 20/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 1.4967 - mse: 0.0095 - val_loss: 1.3651 - val_mse: 0.0066\n",
      "Epoch 21/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 1.2531 - mse: 0.0086 - val_loss: 1.1443 - val_mse: 0.0076\n",
      "Epoch 22/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 1.0502 - mse: 0.0083 - val_loss: 0.9578 - val_mse: 0.0053\n",
      "Epoch 23/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.8822 - mse: 0.0083 - val_loss: 0.8049 - val_mse: 0.0049\n",
      "Epoch 24/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.7427 - mse: 0.0077 - val_loss: 0.6787 - val_mse: 0.0048\n",
      "Epoch 25/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.6281 - mse: 0.0079 - val_loss: 0.5746 - val_mse: 0.0052\n",
      "Epoch 26/100\n",
      "587/587 [==============================] - 24s 41ms/step - loss: 0.5327 - mse: 0.0080 - val_loss: 0.4893 - val_mse: 0.0068\n",
      "Epoch 27/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 0.4524 - mse: 0.0077 - val_loss: 0.4149 - val_mse: 0.0060\n",
      "Epoch 28/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.3850 - mse: 0.0078 - val_loss: 0.3514 - val_mse: 0.0044\n",
      "Epoch 29/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.3276 - mse: 0.0077 - val_loss: 0.3022 - val_mse: 0.0082\n",
      "Epoch 30/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.2782 - mse: 0.0072 - val_loss: 0.2551 - val_mse: 0.0063\n",
      "Epoch 31/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.2366 - mse: 0.0076 - val_loss: 0.2150 - val_mse: 0.0050\n",
      "Epoch 32/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.2001 - mse: 0.0073 - val_loss: 0.1847 - val_mse: 0.0082\n",
      "Epoch 33/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.1690 - mse: 0.0072 - val_loss: 0.1530 - val_mse: 0.0052\n",
      "Epoch 34/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.1426 - mse: 0.0075 - val_loss: 0.1289 - val_mse: 0.0058\n",
      "Epoch 35/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.1197 - mse: 0.0073 - val_loss: 0.1069 - val_mse: 0.0047\n",
      "Epoch 36/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.1003 - mse: 0.0073 - val_loss: 0.0893 - val_mse: 0.0049\n",
      "Epoch 37/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0839 - mse: 0.0073 - val_loss: 0.0762 - val_mse: 0.0067\n",
      "Epoch 38/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0698 - mse: 0.0069 - val_loss: 0.0618 - val_mse: 0.0049\n",
      "Epoch 39/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0589 - mse: 0.0074 - val_loss: 0.0508 - val_mse: 0.0043\n",
      "Epoch 40/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0490 - mse: 0.0068 - val_loss: 0.0430 - val_mse: 0.0049\n",
      "Epoch 41/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0415 - mse: 0.0071 - val_loss: 0.0368 - val_mse: 0.0057\n",
      "Epoch 42/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 0.0351 - mse: 0.0069 - val_loss: 0.0299 - val_mse: 0.0044\n",
      "Epoch 43/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 0.0303 - mse: 0.0070 - val_loss: 0.0283 - val_mse: 0.0071\n",
      "Epoch 44/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 0.0264 - mse: 0.0071 - val_loss: 0.0221 - val_mse: 0.0046\n",
      "Epoch 45/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 0.0227 - mse: 0.0064 - val_loss: 0.0203 - val_mse: 0.0054\n",
      "Epoch 46/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0207 - mse: 0.0069 - val_loss: 0.0191 - val_mse: 0.0062\n",
      "Epoch 47/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0185 - mse: 0.0064 - val_loss: 0.0172 - val_mse: 0.0059\n",
      "Epoch 48/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0174 - mse: 0.0068 - val_loss: 0.0151 - val_mse: 0.0049\n",
      "Epoch 49/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0160 - mse: 0.0064 - val_loss: 0.0143 - val_mse: 0.0050\n",
      "Epoch 50/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0157 - mse: 0.0069 - val_loss: 0.0134 - val_mse: 0.0049\n",
      "Epoch 51/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0150 - mse: 0.0067 - val_loss: 0.0138 - val_mse: 0.0059\n",
      "Epoch 52/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0142 - mse: 0.0064 - val_loss: 0.0118 - val_mse: 0.0042\n",
      "Epoch 53/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0136 - mse: 0.0062 - val_loss: 0.0119 - val_mse: 0.0045\n",
      "Epoch 54/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0138 - mse: 0.0067 - val_loss: 0.0106 - val_mse: 0.0036\n",
      "Epoch 55/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0133 - mse: 0.0064 - val_loss: 0.0132 - val_mse: 0.0063\n",
      "Epoch 56/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0124 - mse: 0.0057 - val_loss: 0.0116 - val_mse: 0.0049\n",
      "Epoch 57/100\n",
      "587/587 [==============================] - 24s 41ms/step - loss: 0.0129 - mse: 0.0063 - val_loss: 0.0132 - val_mse: 0.0067\n",
      "Epoch 58/100\n",
      "587/587 [==============================] - 24s 41ms/step - loss: 0.0127 - mse: 0.0063 - val_loss: 0.0117 - val_mse: 0.0055\n",
      "Epoch 59/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0123 - mse: 0.0060 - val_loss: 0.0107 - val_mse: 0.0045\n",
      "Epoch 60/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0125 - mse: 0.0064 - val_loss: 0.0112 - val_mse: 0.0053\n",
      "Epoch 61/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0123 - mse: 0.0063 - val_loss: 0.0107 - val_mse: 0.0048\n",
      "Epoch 62/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0121 - mse: 0.0062 - val_loss: 0.0097 - val_mse: 0.0038\n",
      "Epoch 63/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0122 - mse: 0.0064 - val_loss: 0.0126 - val_mse: 0.0069\n",
      "Epoch 64/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0119 - mse: 0.0063 - val_loss: 0.0108 - val_mse: 0.0053\n",
      "Epoch 65/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0117 - mse: 0.0061 - val_loss: 0.0076 - val_mse: 0.0021\n",
      "Epoch 66/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0117 - mse: 0.0062 - val_loss: 0.0108 - val_mse: 0.0053\n",
      "Epoch 67/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0116 - mse: 0.0063 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 68/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0114 - mse: 0.0061 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 69/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0117 - mse: 0.0066 - val_loss: 0.0094 - val_mse: 0.0042\n",
      "Epoch 70/100\n",
      "587/587 [==============================] - 24s 41ms/step - loss: 0.0117 - mse: 0.0066 - val_loss: 0.0081 - val_mse: 0.0031\n",
      "Epoch 71/100\n",
      "587/587 [==============================] - 24s 41ms/step - loss: 0.0108 - mse: 0.0058 - val_loss: 0.0112 - val_mse: 0.0062\n",
      "Epoch 72/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0111 - mse: 0.0062 - val_loss: 0.0073 - val_mse: 0.0025\n",
      "Epoch 73/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0110 - mse: 0.0062 - val_loss: 0.0111 - val_mse: 0.0064\n",
      "Epoch 74/100\n",
      "587/587 [==============================] - 24s 42ms/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0079 - val_mse: 0.0032\n",
      "Epoch 75/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0109 - mse: 0.0062 - val_loss: 0.0084 - val_mse: 0.0038\n",
      "Epoch 76/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0111 - mse: 0.0065 - val_loss: 0.0071 - val_mse: 0.0025\n",
      "Epoch 77/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0109 - mse: 0.0063 - val_loss: 0.0075 - val_mse: 0.0030\n",
      "Epoch 78/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0105 - mse: 0.0060 - val_loss: 0.0093 - val_mse: 0.0049\n",
      "Epoch 79/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0103 - mse: 0.0058 - val_loss: 0.0088 - val_mse: 0.0043\n",
      "Epoch 80/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0104 - mse: 0.0060 - val_loss: 0.0087 - val_mse: 0.0044\n",
      "Epoch 81/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0103 - mse: 0.0060 - val_loss: 0.0105 - val_mse: 0.0062\n",
      "Epoch 82/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0103 - mse: 0.0061 - val_loss: 0.0074 - val_mse: 0.0031\n",
      "Epoch 83/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0102 - mse: 0.0060 - val_loss: 0.0072 - val_mse: 0.0030\n",
      "Epoch 84/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0100 - mse: 0.0059 - val_loss: 0.0095 - val_mse: 0.0054\n",
      "Epoch 85/100\n",
      "587/587 [==============================] - 25s 43ms/step - loss: 0.0099 - mse: 0.0058 - val_loss: 0.0075 - val_mse: 0.0035\n",
      "Epoch 86/100\n",
      "587/587 [==============================] - 25s 42ms/step - loss: 0.0098 - mse: 0.0058 - val_loss: 0.0077 - val_mse: 0.0037\n"
     ]
    }
   ],
   "source": [
    "# Train cost calculator and encoder\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "with tf.device(\"gpu:0\"):\n",
    "    enc_cost_calc = models.Sequential([layers.Input(shape=IMG_INPUT_SHAPE), encoder, cost_calculator])\n",
    "    enc_cost_calc.compile(optimizers.Adam(learning_rate=ENCODER_AND_COST_LR), loss=\"mse\", metrics=[\"mse\"])\n",
    "    enc_cost_calc.summary()\n",
    "    \n",
    "    frame_and_score = lambda w, x, y, z: (w, z)\n",
    "    \n",
    "    enc_cost_calc.fit(\n",
    "        big_train_ds.map(frame_and_score, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False).batch(BATCH_SIZE),\n",
    "        validation_data=big_valid_ds.map(frame_and_score, num_parallel_calls=tf.data.AUTOTUNE, deterministic=False).batch(BATCH_SIZE),\n",
    "        epochs=MAX_EPOCHS,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=MAX_EPOCHS//10, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "encoder.trainable = False\n",
    "cost_calculator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d83dd-48e4-402d-9638-f4e40cd6245e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 64)                2368      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12768 (49.88 KB)\n",
      "Trainable params: 12768 (49.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "587/587 [==============================] - 130s 217ms/step - loss: 1.8730 - mse: 0.1519 - val_loss: 1.7847 - val_mse: 0.0884\n",
      "Epoch 2/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.7912 - mse: 0.1201 - val_loss: 1.7128 - val_mse: 0.0674\n",
      "Epoch 3/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.7192 - mse: 0.0996 - val_loss: 1.6468 - val_mse: 0.0532\n",
      "Epoch 4/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.6522 - mse: 0.0847 - val_loss: 1.5842 - val_mse: 0.0428\n",
      "Epoch 5/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.5874 - mse: 0.0721 - val_loss: 1.5239 - val_mse: 0.0348\n",
      "Epoch 6/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.5262 - mse: 0.0630 - val_loss: 1.4656 - val_mse: 0.0285\n",
      "Epoch 7/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.4663 - mse: 0.0551 - val_loss: 1.4089 - val_mse: 0.0235\n",
      "Epoch 8/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.4081 - mse: 0.0484 - val_loss: 1.3537 - val_mse: 0.0197\n",
      "Epoch 9/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.3514 - mse: 0.0426 - val_loss: 1.3000 - val_mse: 0.0165\n",
      "Epoch 10/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.2966 - mse: 0.0380 - val_loss: 1.2476 - val_mse: 0.0140\n",
      "Epoch 11/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.2431 - mse: 0.0340 - val_loss: 1.1966 - val_mse: 0.0120\n",
      "Epoch 12/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.1910 - mse: 0.0306 - val_loss: 1.1469 - val_mse: 0.0104\n",
      "Epoch 13/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.1404 - mse: 0.0276 - val_loss: 1.0984 - val_mse: 0.0091\n",
      "Epoch 14/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.0913 - mse: 0.0251 - val_loss: 1.0513 - val_mse: 0.0081\n",
      "Epoch 15/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 1.0434 - mse: 0.0227 - val_loss: 1.0054 - val_mse: 0.0072\n",
      "Epoch 16/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.9971 - mse: 0.0209 - val_loss: 0.9608 - val_mse: 0.0065\n",
      "Epoch 17/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.9522 - mse: 0.0193 - val_loss: 0.9175 - val_mse: 0.0059\n",
      "Epoch 18/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.9084 - mse: 0.0177 - val_loss: 0.8755 - val_mse: 0.0055\n",
      "Epoch 19/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.8661 - mse: 0.0163 - val_loss: 0.8347 - val_mse: 0.0051\n",
      "Epoch 20/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.8253 - mse: 0.0152 - val_loss: 0.7953 - val_mse: 0.0047\n",
      "Epoch 21/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.7856 - mse: 0.0141 - val_loss: 0.7570 - val_mse: 0.0044\n",
      "Epoch 22/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.7474 - mse: 0.0132 - val_loss: 0.7201 - val_mse: 0.0043\n",
      "Epoch 23/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.7104 - mse: 0.0124 - val_loss: 0.6843 - val_mse: 0.0040\n",
      "Epoch 24/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.6746 - mse: 0.0115 - val_loss: 0.6498 - val_mse: 0.0038\n",
      "Epoch 25/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.6403 - mse: 0.0109 - val_loss: 0.6165 - val_mse: 0.0037\n",
      "Epoch 26/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.6075 - mse: 0.0106 - val_loss: 0.5844 - val_mse: 0.0034\n",
      "Epoch 27/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.5753 - mse: 0.0098 - val_loss: 0.5535 - val_mse: 0.0034\n",
      "Epoch 28/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.5446 - mse: 0.0093 - val_loss: 0.5238 - val_mse: 0.0032\n",
      "Epoch 29/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.5151 - mse: 0.0089 - val_loss: 0.4951 - val_mse: 0.0031\n",
      "Epoch 30/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.4867 - mse: 0.0084 - val_loss: 0.4676 - val_mse: 0.0031\n",
      "Epoch 31/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.4594 - mse: 0.0080 - val_loss: 0.4413 - val_mse: 0.0030\n",
      "Epoch 32/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.4334 - mse: 0.0078 - val_loss: 0.4159 - val_mse: 0.0029\n",
      "Epoch 33/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.4082 - mse: 0.0073 - val_loss: 0.3917 - val_mse: 0.0029\n",
      "Epoch 34/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.3844 - mse: 0.0073 - val_loss: 0.3684 - val_mse: 0.0028\n",
      "Epoch 35/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.3615 - mse: 0.0069 - val_loss: 0.3462 - val_mse: 0.0028\n",
      "Epoch 36/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.3395 - mse: 0.0066 - val_loss: 0.3250 - val_mse: 0.0027\n",
      "Epoch 37/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.3186 - mse: 0.0064 - val_loss: 0.3047 - val_mse: 0.0026\n",
      "Epoch 38/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.2986 - mse: 0.0062 - val_loss: 0.2854 - val_mse: 0.0026\n",
      "Epoch 39/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.2796 - mse: 0.0061 - val_loss: 0.2669 - val_mse: 0.0026\n",
      "Epoch 40/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.2615 - mse: 0.0059 - val_loss: 0.2494 - val_mse: 0.0026\n",
      "Epoch 41/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.2443 - mse: 0.0058 - val_loss: 0.2327 - val_mse: 0.0024\n",
      "Epoch 42/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.2278 - mse: 0.0056 - val_loss: 0.2168 - val_mse: 0.0024\n",
      "Epoch 43/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.2123 - mse: 0.0054 - val_loss: 0.2018 - val_mse: 0.0024\n",
      "Epoch 44/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1976 - mse: 0.0053 - val_loss: 0.1875 - val_mse: 0.0023\n",
      "Epoch 45/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1837 - mse: 0.0052 - val_loss: 0.1741 - val_mse: 0.0023\n",
      "Epoch 46/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1704 - mse: 0.0051 - val_loss: 0.1613 - val_mse: 0.0023\n",
      "Epoch 47/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1580 - mse: 0.0050 - val_loss: 0.1493 - val_mse: 0.0022\n",
      "Epoch 48/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1462 - mse: 0.0048 - val_loss: 0.1380 - val_mse: 0.0022\n",
      "Epoch 49/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1351 - mse: 0.0047 - val_loss: 0.1274 - val_mse: 0.0023\n",
      "Epoch 50/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1249 - mse: 0.0048 - val_loss: 0.1174 - val_mse: 0.0022\n",
      "Epoch 51/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1151 - mse: 0.0045 - val_loss: 0.1081 - val_mse: 0.0022\n",
      "Epoch 52/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.1059 - mse: 0.0044 - val_loss: 0.0994 - val_mse: 0.0022\n",
      "Epoch 53/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0975 - mse: 0.0044 - val_loss: 0.0912 - val_mse: 0.0021\n",
      "Epoch 54/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0895 - mse: 0.0042 - val_loss: 0.0836 - val_mse: 0.0020\n",
      "Epoch 55/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0822 - mse: 0.0042 - val_loss: 0.0765 - val_mse: 0.0020\n",
      "Epoch 56/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0753 - mse: 0.0041 - val_loss: 0.0699 - val_mse: 0.0020\n",
      "Epoch 57/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0690 - mse: 0.0041 - val_loss: 0.0639 - val_mse: 0.0020\n",
      "Epoch 58/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0631 - mse: 0.0041 - val_loss: 0.0583 - val_mse: 0.0020\n",
      "Epoch 59/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0577 - mse: 0.0040 - val_loss: 0.0532 - val_mse: 0.0020\n",
      "Epoch 60/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0527 - mse: 0.0039 - val_loss: 0.0484 - val_mse: 0.0019\n",
      "Epoch 61/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0482 - mse: 0.0039 - val_loss: 0.0442 - val_mse: 0.0020\n",
      "Epoch 62/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0441 - mse: 0.0038 - val_loss: 0.0402 - val_mse: 0.0019\n",
      "Epoch 63/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0403 - mse: 0.0038 - val_loss: 0.0367 - val_mse: 0.0019\n",
      "Epoch 64/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0367 - mse: 0.0036 - val_loss: 0.0335 - val_mse: 0.0020\n",
      "Epoch 65/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0338 - mse: 0.0037 - val_loss: 0.0306 - val_mse: 0.0019\n",
      "Epoch 66/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0310 - mse: 0.0036 - val_loss: 0.0280 - val_mse: 0.0018\n",
      "Epoch 67/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0285 - mse: 0.0035 - val_loss: 0.0256 - val_mse: 0.0018\n",
      "Epoch 68/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0263 - mse: 0.0036 - val_loss: 0.0236 - val_mse: 0.0018\n",
      "Epoch 69/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0243 - mse: 0.0035 - val_loss: 0.0218 - val_mse: 0.0018\n",
      "Epoch 70/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0226 - mse: 0.0034 - val_loss: 0.0202 - val_mse: 0.0018\n",
      "Epoch 71/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0211 - mse: 0.0034 - val_loss: 0.0188 - val_mse: 0.0017\n",
      "Epoch 72/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0197 - mse: 0.0034 - val_loss: 0.0176 - val_mse: 0.0018\n",
      "Epoch 73/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0186 - mse: 0.0033 - val_loss: 0.0165 - val_mse: 0.0017\n",
      "Epoch 74/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0175 - mse: 0.0032 - val_loss: 0.0156 - val_mse: 0.0017\n",
      "Epoch 75/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0167 - mse: 0.0032 - val_loss: 0.0148 - val_mse: 0.0017\n",
      "Epoch 76/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0160 - mse: 0.0032 - val_loss: 0.0141 - val_mse: 0.0017\n",
      "Epoch 77/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0153 - mse: 0.0032 - val_loss: 0.0136 - val_mse: 0.0017\n",
      "Epoch 78/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0148 - mse: 0.0031 - val_loss: 0.0131 - val_mse: 0.0017\n",
      "Epoch 79/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0143 - mse: 0.0032 - val_loss: 0.0126 - val_mse: 0.0017\n",
      "Epoch 80/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0138 - mse: 0.0030 - val_loss: 0.0123 - val_mse: 0.0016\n",
      "Epoch 81/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0135 - mse: 0.0031 - val_loss: 0.0120 - val_mse: 0.0016\n",
      "Epoch 82/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0131 - mse: 0.0030 - val_loss: 0.0117 - val_mse: 0.0016\n",
      "Epoch 83/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0129 - mse: 0.0030 - val_loss: 0.0115 - val_mse: 0.0016\n",
      "Epoch 84/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0127 - mse: 0.0030 - val_loss: 0.0112 - val_mse: 0.0016\n",
      "Epoch 85/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0125 - mse: 0.0030 - val_loss: 0.0111 - val_mse: 0.0016\n",
      "Epoch 86/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0124 - mse: 0.0030 - val_loss: 0.0109 - val_mse: 0.0016\n",
      "Epoch 87/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0122 - mse: 0.0029 - val_loss: 0.0108 - val_mse: 0.0016\n",
      "Epoch 88/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0120 - mse: 0.0029 - val_loss: 0.0107 - val_mse: 0.0017\n",
      "Epoch 89/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0119 - mse: 0.0029 - val_loss: 0.0106 - val_mse: 0.0017\n",
      "Epoch 90/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0118 - mse: 0.0029 - val_loss: 0.0104 - val_mse: 0.0016\n",
      "Epoch 91/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0116 - mse: 0.0028 - val_loss: 0.0104 - val_mse: 0.0016\n",
      "Epoch 92/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0115 - mse: 0.0028 - val_loss: 0.0103 - val_mse: 0.0016\n",
      "Epoch 93/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0115 - mse: 0.0028 - val_loss: 0.0102 - val_mse: 0.0016\n",
      "Epoch 94/100\n",
      "587/587 [==============================] - 4s 7ms/step - loss: 0.0114 - mse: 0.0028 - val_loss: 0.0101 - val_mse: 0.0016\n",
      "Epoch 95/100\n",
      "313/587 [==============>...............] - ETA: 1s - loss: 0.0114 - mse: 0.0029"
     ]
    }
   ],
   "source": [
    "# Train prediction\n",
    "with tf.device(\"cpu:0\"):\n",
    "    apply_encoder = lambda w, x, y, z: (tf.concat([tf.cast(encoder(w), tf.float16), y], axis=-1), tf.cast(encoder(x), tf.float16))\n",
    "    pred_train_ds = big_train_ds.batch(BATCH_SIZE).map(apply_encoder, num_parallel_calls=BATCH_SIZE//4, deterministic=False).cache()\n",
    "    pred_valid_ds = big_valid_ds.batch(BATCH_SIZE).map(apply_encoder, num_parallel_calls=BATCH_SIZE//4, deterministic=False).cache()\n",
    "\n",
    "with tf.device(\"gpu:0\"):\n",
    "    predictor.compile(optimizers.Adam(learning_rate=PRED_LR), loss=\"mse\", metrics=[\"mse\"])\n",
    "    predictor.summary()\n",
    "    \n",
    "    predictor.fit(\n",
    "        pred_train_ds,\n",
    "        validation_data=pred_valid_ds,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=MAX_EPOCHS//10, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "predictor.trainable=False"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51acdf18-12b7-4907-b8f0-5ee28cb7a9ad",
   "metadata": {},
   "source": [
    "We know the ground truth of the predicted action's cost function.  Maybe a better way would be to alternate between batch of encoder->cost and encoder->prediction->cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c6a12d-05b0-424b-bdcd-4ab0b92d43f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 127s 20ms/step - loss: 0.2706 - minimize_loss: 0.2605 - val_loss: 0.2722 - val_minimize_loss: 0.2621\n",
      "Epoch 2/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2704 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 3/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 4/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 5/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2704 - minimize_loss: 0.2603 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 6/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 7/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2704 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 8/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 9/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 10/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 11/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 12/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2705 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 13/100\n",
      "6250/6250 [==============================] - 74s 12ms/step - loss: 0.2704 - minimize_loss: 0.2604 - val_loss: 0.2722 - val_minimize_loss: 0.2620\n",
      "Epoch 14/100\n",
      "5842/6250 [===========================>..] - ETA: 4s - loss: 0.2706 - minimize_loss: 0.2605"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m action_gen_trainer\u001b[38;5;241m.\u001b[39mcompile(optimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mACT_GEN_LR), loss\u001b[38;5;241m=\u001b[39mminimize_loss, metrics\u001b[38;5;241m=\u001b[39m[minimize_loss])\n\u001b[1;32m     18\u001b[0m action_gen_trainer\u001b[38;5;241m.\u001b[39msummary(show_trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43maction_gen_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactgen_train_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactgen_valid_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_EPOCHS\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train action generator\n",
    "def minimize_loss(y_true, y_pred):\n",
    "    return tf.math.reduce_mean(y_pred)\n",
    "\n",
    "\n",
    "with tf.device(\"cpu:0\"):\n",
    "    apply_encoder = lambda w, x, y, z: (tf.cast(encoder(w), tf.float16), z)\n",
    "    actgen_valid_ds = big_valid_ds.batch(BATCH_SIZE).map(apply_encoder, num_parallel_calls=BATCH_SIZE//4, deterministic=False).cache()\n",
    "    actgen_train_ds = tf.data.Dataset.from_tensor_slices((tf.random.normal((100_000, OUTPUT_SIZE)), tf.zeros(100_000, 1))).batch(BATCH_SIZE)\n",
    "\n",
    "model_in = layers.Input(shape=OUTPUT_SIZE)\n",
    "action_gen_trainer = layers.Concatenate()([model_in, action_gen(model_in)])\n",
    "action_gen_trainer = predictor(action_gen_trainer)\n",
    "action_gen_trainer = cost_calculator(action_gen_trainer)\n",
    "action_gen_trainer = models.Model(model_in, action_gen_trainer)\n",
    "\n",
    "action_gen_trainer.compile(optimizers.Adam(learning_rate=ACT_GEN_LR), loss=minimize_loss, metrics=[minimize_loss])\n",
    "action_gen_trainer.summary(show_trainable=True)\n",
    "\n",
    "action_gen_trainer.fit(\n",
    "    actgen_train_ds,\n",
    "    validation_data=actgen_valid_ds,\n",
    "    epochs=MAX_EPOCHS,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=MAX_EPOCHS//10, restore_best_weights=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80b5148a-b409-461a-a9f3-ae34620a8f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model so it can play the game\n",
    "\n",
    "pred_model = models.Sequential([layers.Input(shape=IMG_INPUT_SHAPE), encoder, action_gen])\n",
    "pred_model.save(\"prediction_model_%s.keras\" % ROLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d601c3d-247c-414f-a242-f3d0d0494c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
